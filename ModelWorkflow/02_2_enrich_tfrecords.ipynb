{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a7e9b8c-ab9c-4eac-a426-8a2a3e16bd9b",
   "metadata": {},
   "source": [
    "## 2.2 - Enrich Tfrecords\n",
    "\n",
    "Code that Modifies the Processed Tfrecords (Files in root/Datasets/SelectedClusters/nexus_tfrecords_processed\n",
    "\n",
    "to add the other two indicators left (longevity and literacy) in the process method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5091e937-50da-476d-8082-a023ec63ee91",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8af4f8a-9030-4847-b5c1-034f684db5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6644011-464d-430d-b0d9-c885a0993753",
   "metadata": {},
   "source": [
    "Paths to Required Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2fa89b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to processed Tfrecords - Created in Code 02\n",
    "tfrecords_path = \"/root/Datasets/SelectedClusters/nexus_tfrecords_processed/brazil_2010\"\n",
    "# Path to .csv File, where info about the indicators are stored - Created in Preprocessing\n",
    "csv_path = \"/root/Datasets/SelectedClusters\"\n",
    "\n",
    "# Path to new Processed Tfrecords - Output of this File\n",
    "new_tfrecords_path = \"/root/Datasets/SelectedClusters/nexus_tfrecords_processed_new/brazil_2010\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cfe52f2-0000-4a5f-9c0f-147d4880ab9a",
   "metadata": {},
   "source": [
    "Creating a list containing all the Filenames of the Processed Tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebd6d48-fbc6-4b2f-ae67-324850a1eeca",
   "metadata": {},
   "outputs": [],
   "source": [
    "filenames = glob.glob(os.path.join(tfrecords_path, \"*.tfrecord.gz\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8704faee-f8c8-45dc-a337-58d52d86497e",
   "metadata": {},
   "source": [
    "Configuration to save the new Tfrecords in .gz format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df978f9c-ba82-4754-97df-c51ca6e50ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "options = tf.io.TFRecordOptions(compression_type = 'GZIP')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10520cae-8681-4295-98da-af6be69ca6f0",
   "metadata": {},
   "source": [
    "Loading the DataFrame and Changing Format\n",
    "\n",
    "- Float64 -> Float 32\n",
    "- String (Object) -> Bytes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02256c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(os.path.join(csv_path,'dataset_clean.csv'), float_precision='high')\n",
    "for col in dataset.columns:\n",
    "        if dataset[col].dtype == np.float64:\n",
    "            dataset[col] = dataset[col].astype(np.float32)\n",
    "        elif dataset[col].dtype == object:  # pandas uses 'object' type for str\n",
    "            dataset[col] = dataset[col].astype(bytes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3893bfd2-d656-4a94-8fe8-e40b2a48de78",
   "metadata": {},
   "source": [
    "Verifying Changes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f34b3fae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>literacy</th>\n",
       "      <th>longevity</th>\n",
       "      <th>income</th>\n",
       "      <th>year</th>\n",
       "      <th>TYPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'brazil'</td>\n",
       "      <td>-60.100670</td>\n",
       "      <td>-12.772811</td>\n",
       "      <td>0.963506</td>\n",
       "      <td>0.768335</td>\n",
       "      <td>0.628482</td>\n",
       "      <td>2010</td>\n",
       "      <td>b'URBAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'brazil'</td>\n",
       "      <td>-48.270237</td>\n",
       "      <td>-7.218174</td>\n",
       "      <td>0.903346</td>\n",
       "      <td>0.758552</td>\n",
       "      <td>0.520860</td>\n",
       "      <td>2010</td>\n",
       "      <td>b'URBAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'brazil'</td>\n",
       "      <td>-48.210049</td>\n",
       "      <td>-7.157114</td>\n",
       "      <td>0.926798</td>\n",
       "      <td>0.781569</td>\n",
       "      <td>0.580544</td>\n",
       "      <td>2010</td>\n",
       "      <td>b'URBAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'brazil'</td>\n",
       "      <td>-49.162132</td>\n",
       "      <td>-11.892742</td>\n",
       "      <td>0.907821</td>\n",
       "      <td>0.790722</td>\n",
       "      <td>0.476975</td>\n",
       "      <td>2010</td>\n",
       "      <td>b'URBAN'</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'brazil'</td>\n",
       "      <td>-48.468857</td>\n",
       "      <td>-8.062309</td>\n",
       "      <td>0.932752</td>\n",
       "      <td>0.778629</td>\n",
       "      <td>0.543212</td>\n",
       "      <td>2010</td>\n",
       "      <td>b'URBAN'</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     country        lon        lat  literacy  longevity    income  year  \\\n",
       "0  b'brazil' -60.100670 -12.772811  0.963506   0.768335  0.628482  2010   \n",
       "1  b'brazil' -48.270237  -7.218174  0.903346   0.758552  0.520860  2010   \n",
       "2  b'brazil' -48.210049  -7.157114  0.926798   0.781569  0.580544  2010   \n",
       "3  b'brazil' -49.162132 -11.892742  0.907821   0.790722  0.476975  2010   \n",
       "4  b'brazil' -48.468857  -8.062309  0.932752   0.778629  0.543212  2010   \n",
       "\n",
       "       TYPE  \n",
       "0  b'URBAN'  \n",
       "1  b'URBAN'  \n",
       "2  b'URBAN'  \n",
       "3  b'URBAN'  \n",
       "4  b'URBAN'  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da9ca87-4372-4266-8795-61d83ed71473",
   "metadata": {},
   "source": [
    "Function that transform an Dict into String - whats written on the Tfrecords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4d1cca69",
   "metadata": {},
   "outputs": [],
   "source": [
    "def serialize(record):\n",
    "    serializable_record = {key : feature for key, (feature, _) in record.items()}\n",
    "    record_example = tf.train.Example(features=tf.train.Features(feature=serializable_record))\n",
    "    return record_example.SerializeToString()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e271c1d8-fb33-4a9b-a171-6f690a2acf31",
   "metadata": {},
   "source": [
    "Algorith that injects the new data onto the Tfrecords, creating new ones\n",
    "\n",
    "Loop for each Tfrecord File\n",
    "- Loading the Tfrecord\n",
    "- Parsing and extracting the Features form the String\n",
    "- Creating a dictionary with the features\n",
    "- Searching the .csv file for the same location (through Latitude and Longitude)\n",
    "- Creating new features to put together with the old ones\n",
    "- Coding the Dictionary into the String again\n",
    "- Saving into a new Tfrecord"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "39933a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_data = tf.data.TFRecordDataset(filenames, compression_type = 'GZIP')\n",
    "indicators = [\"literacy\",\"longevity\",\"income\"]\n",
    "\n",
    "for i, raw_record in enumerate(tf_data.take(len(filenames))):\n",
    "    record = {}\n",
    "    example = tf.train.Example()\n",
    "    example.ParseFromString(raw_record.numpy())\n",
    "\n",
    "    # We first map each record feature into a dictionary\n",
    "    for k, feat in example.features.feature.items():\n",
    "        record[k] = (feat, feat.WhichOneof('kind'))\n",
    "\n",
    "    # Now we retrieve lat/lon to match with info in the dataset\n",
    "    # and update the dictionary\n",
    "    recorded_lat_tuple = record[\"lat\"]\n",
    "    recorded_lon_tuple = record[\"lon\"]\n",
    "    lat = getattr(*recorded_lat_tuple).value[0]\n",
    "    lon = getattr(*recorded_lon_tuple).value[0]\n",
    "    row = dataset[(dataset['lon'] == lon) & (dataset['lat'] == lat)].reset_index()\n",
    "\n",
    "    # Now we update the record with each indicator value\n",
    "    for indicator in indicators:\n",
    "        feat = tf.train.Feature(float_list=tf.train.FloatList(value=[row[indicator]]))\n",
    "        record[indicator] = (feat, feat.WhichOneof('kind'))\n",
    "        \n",
    "    serialized_string = serialize(record)\n",
    "    with tf.io.TFRecordWriter(os.path.join(new_tfrecords_path, f'{i:05d}.tfrecord.gz'), options=options) as writer:\n",
    "        writer.write(serialized_string)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1423b606-9b90-4d6d-9563-cd9552e6e5d2",
   "metadata": {},
   "source": [
    "Verifying the Process - Amount of Files Created\n",
    "\n",
    "Must have the same amount (20438)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fd759236",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File count: 20438\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# folder path\n",
    "dir_path = \"/root/Datasets/SelectedClusters/nexus_tfrecords_processed_new/brazil_2010/\"\n",
    "count = 0\n",
    "# Iterate directory\n",
    "for path in os.listdir(dir_path):\n",
    "    # check if current path is a file\n",
    "    if os.path.isfile(os.path.join(dir_path, path)):\n",
    "        count += 1\n",
    "print('File count:', count)"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.m5.4xlarge",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.3 Python 3.7 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.3-cpu-py37-ubuntu18.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  },
  "vscode": {
   "interpreter": {
    "hash": "61eb07f8ada5ae54bc3896e2106e770f6fe833c0139389ad99016c36202a4622"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
